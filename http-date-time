#!/usr/bin/env python3
from pathlib import Path
from random import choice
from ssl import create_default_context
from subprocess import run
from sys import argv
from urllib.error import URLError
from urllib.request import build_opener,install_opener,ProxyHandler,urlopen

#############
### USAGE ###
#############
def usage():
    name = Path(__file__).name
    print(f"NAME\n\t{name} - set the date and time using HTTP headers\n")
    print(f"SYNPOSIS\n\t{name} [OPTIONS]\n")
    print(f"DESCRIPTION\n\t{name} obtains the date and time from HTTP headers rather than NTP, which is unencrypted and susceptible to time attacks. By default, only non-Tor/clearnet URLs are used but Tor mode can be enabled to connect to only onion domains instead.\n")
    print(f"OPTIONS")
    print("\t--help\t\t\tShow this message")
    print("\t--pool [filename]\tSpecify a custom text file containing the sources to use")
    print("\t--tor\t\t\tEnable Tor mode")
    print("\nEXAMPLES")
    print(f"\t1) {name}")
    print(f"\t2) {name} --pool /usr/local/etc/http-date-time/pool.txt")
    print(f"\t3) {name} --tor")
    print(f"\t4) {name} --pool /usr/local/etc/http-date-time/pool.txt --tor")
    print("\n")

################
### MESSAGES ###
################
def error(msg = False):
    # If a $msg was specified, then display it to stdout
    if msg: print(f"!-- ERROR: {msg}")
    # Exit with error 1
    exit(1)

def info(msg):
    # Display an informational message to stdout
    print(f"!-- INFO: {msg}")

def warn(msg):
    # Display a warning message to stdout
    print(f"!-- WARN: {msg}")

#################
### FUNCTIONS ###
#################
def args():
    #
    if flags('--help'):
        usage()
        exit(0)
    # Tor mode; check if the Tor flag was passed which makes the script use onion domains
    tor_mode = flags('--tor')
    # Sources (Optional); check of the user has specified a text file that contains the pool of URLs to use
    pool_txt = flags('--pool', get_value = True)
    # If the user has not specified a text file containing the pool of sources, then default to '/etc/http-date-time/pool.txt'
    if pool_txt is False: pool_txt = Path('/etc', 'http-date-time', 'pool.txt')
    # Return the arguments
    return(tor_mode, pool_txt)

def flags(name, get_value = False):
    # Iterate through all arguments
    for i in range(len(argv)):
        # Define the current argument
        arg = argv[i]
        # Check if the current $arg matches the specified $name
        if arg == name:
            # If there is no value for $arg then return bool True
            if get_value is False: return(True)
            try:
                # Return the value of $arg, which should be the next argument in the $argv list
                return(argv[i + 1])
            except IndexError:
                # If there is no value for $arg, then display a warning to stdout
                warn(f"Unable to obtain the value for: '{name}'")
                # Return bool False
                return(False)
    # If $name was not found in list $argv, return bool False
    return(False)

def read(tor_mode, pool_txt):
    # If the $pool_txt is not a valid file, then display an error message to stdout and exit 1
    if not Path(pool_txt).is_file(): error(f"Unable to locate the file: '{pool_txt}'")
    # Display whether Tor mode is enabled or not to stdout
    info(f"Tor mode: {tor_mode}")
    # Open $pool_txt and obtain its contents
    with open(pool_txt, 'r') as f: contents = f.readlines()
    # Keep only lines that are non-empty and remove extraneous whitespace from each line
    contents = [line.strip() for line in contents if line.strip()]
    # Keep only lines that do not start with '#'; in other words, remove all comments
    contents = [line for line in contents if not line.startswith('#')]
    # Define the pool to be all URLs that do not start with the specified string; this creates a pool of clearnet URLs
    pool = [line for line in contents if not line.startswith('tor:')]
    # Check if Tor mode is enabled
    if tor_mode is True:
        # If so, then define the pool to be all URLs within $contents that are not within $pool. This obtains the Tor onion URLs
        pool = set(pool).symmetric_difference(set(contents))
        # Remove the string at the beginning of each Tor URL
        pool = [url.split(':', 1)[1] for url in pool]
    # Return the $pool
    return(pool)

def ssl():
    # Define Python's default SSL context
    context = create_default_context()
    # [DISABLED] Enforce the same TLS version for the minimum as the maximum. For now this causes issues with the URLs, so use the default
    #context.minimum_version = context.maximum_version
    # Return the SSL context
    return(context)

def fetch(pool, tor_mode, retry = 0, max_retry = 10):
    # Randomly choose a URL from the $pool
    url = choice(pool)
    # Display the selected $url to stdout
    info(f"Setting the date and time using the following source: {url}")
    # Check if Tor mode is enabled
    if tor_mode is True:
        # Enable the following options if Tor mode is enabled:
        # '--socks5-hostname localhost:9050': Use the given SOCKS5 proxy, which is localhost at port 9050 (Tor)
        options = ['--socks5-hostname', 'localhost:9050']
    else:
        # Otherwise use the following options when connecting to clearnet URLs:
        # '--tlsv1.3': Use TLS v1.3
        # '--proto =https': Only use HTTPS
        options = ['--tlsv1.3', '--proto', '=https']
    # Define the full command to execute using the $options defined above as well as the following other options:
    # '--head': Fetch the HTTP headers only
    # '--silent': Don't show any error messages to stdout
    cmd = ['curl', '--head', '--silent'] + options + ['--url', url]
    # Execute the `curl` command and capture all output, including both stderr and stdout
    request = run(cmd, capture_output = True)
    # Check if the return code was anything but 0, meaning an issue occurred
    if request.returncode != 0:
        # Default to an empty error message
        stderr = ''
        # If there is an error message, then define a string for stdout
        if request.stderr: stderr = f": {request.stderr.decode()}"
        # Display the return code and $stderr, if applicable, to stdout
        error(f"Return code {request.returncode}{stderr}")
    # Check if `curl` did not return any output
    if not request.stdout:
        # If the number of retries is at the maximum, then display an error message to stdout and exit 1
        if retry == max_retry: error(f"Unable to connect to the randomly chosen URLs within the following pool. Please check your connection and try again.\n\n{pool}\n")
        # Display the current number of retries
        info(f"Retry {retry + 1} of {max_retry}")
        # If the request failed, then call this function again while increasing the $retry counter by 1 
        return(fetch(pool, tor_mode, retry = retry + 1))
    # Create a list of all HTTP headers from `request.stdout`
    stdout = [entry.strip() for entry in request.stdout.decode().split('\n')]
    # Return $stdout
    return(stdout)

def http_headers(stdout):
    # Define a dictionary that will contain each HTTP header name as the key and their values
    headers = {}
    # Iterate through each entry within the $stdout list
    for header in stdout:
        # Split the current $header entry via the first semicolon so that index 0 is the header name and index 1 is the value
        s = [entry.strip() for entry in header.split(':', 1)]
        try:
            # Add the HTTP header name (as lowercase) and its value to the $headers dictionary
            headers[s[0].lower()] = s[1]
        except IndexError:
            # If the above command fails, then continue to the next $header within the list. Note that not all entries within $stdout are HTTP headers
            continue
    # Return the $headers dictionary
    return(headers)

def parse(stdout):
    # Parse $stdout and return a dictionary of each header and their value
    headers = http_headers(stdout)
    try:
        # Obtain the date and time from the $headers dictionary
        date = headers['date']
    except KeyError:
        # If the date was not part of the HTTP header from the current $url, then remove it from the $pool
        pool = [source for source in pool if (not source == url)]
        # Display a warning message to stdout
        warn('Unable to extract the date from the HTTP headers of the current source\n')
        # If the $pool is now empty then the date could not be obtained from any of the HTTP headers of any URL within the original $pool, so display an error message to stdout and exit
        if not pool: error('Unable to extract the date from the HTTP headers of all sources')
        # Otherwise, call this function again with the new $pool
        return(fetch(pool, tor_mode))
    # Return the $date
    return(date)

def system(date):
    # Set the date and time for the system. Any errors will be shown to stdout so `capture_output` is not needed 
    run(['date', f"--set={date}"])

############
### MAIN ###
############
def main(tor_mode, pool_txt):
    # Read the $pool_txt file and obtain the pool of URLs to use
    pool = read(tor_mode, pool_txt)
    # Fetch the HTTP headers using `curl` and a randomly selected URL from $pool
    stdout = fetch(pool, tor_mode)
    # Parse the output from the `curl` command used above to obtain the current date and time
    date = parse(stdout)
    # Set the date and time on the system
    system(date)

#############
### START ###
#############
if __name__ == '__main__':
    # User-defined arguments
    [tor_mode, pool_txt] = args()
    # Start the main function
    main(tor_mode, pool_txt)
